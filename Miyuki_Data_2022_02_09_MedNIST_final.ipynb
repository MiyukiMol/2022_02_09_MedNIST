{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4137d126",
   "metadata": {},
   "source": [
    "# Etude sur MedNIST : Classification d'images issues du milieu médical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30167d48",
   "metadata": {},
   "source": [
    "Développer une Intelligence Artificielle capable de reconnaitre la catégorie d'une image médicale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ff402e",
   "metadata": {},
   "source": [
    "Contexte du projet\n",
    "\n",
    "La MedNIST est une base de données de 58 954 images (N&B, 64x64 pixels) issues du milieu médical. Les images sont labellisées en six catégories : AbdomenCT, BreastMRI, CXR, ChestCT, Hand et HeadCT. Le but est de prédire en fonction de l'image sa catégorie.\n",
    "\n",
    "47 163 images vous sont fournies ; l'objectif est d'entrainer le modèle de Machine Learning ou de Deep Learning le plus performant possible : toutes les stratégies sont autorisées, seule la performance prime !\n",
    "\n",
    "Les 11 791 images manquantes constituent le jeu de test : elles ne vous seront pas fournies et serviront à évaluer les performances de votre modèle par le formateur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ad854f",
   "metadata": {},
   "source": [
    "MedNISTは、医療分野の画像（白黒、64x64ピクセル）58,954枚を収録したデータベースです。画像は6つのカテゴリーに分類されています。AbdomenCT、BreastMRI、CXR、ChestCT、Hand、HeadCT。目的は、画像のカテゴリを予測することである。\n",
    "\n",
    "47,163枚の画像が用意されています。目的は、可能な限り最高のパフォーマンスを発揮する機械学習または深層学習モデルを学習することです。あらゆる戦略が可能で、パフォーマンスのみが重要です\n",
    "\n",
    "11,791枚の画像はテストセットで、あなたには提供されず、トレーナーによってあなたのモデルの性能を評価するために使われます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ec40ec",
   "metadata": {},
   "source": [
    "#cp \"/content/drive/MyDrive/Colab Notebooks/2022_02_09_MedNIST/MedNIST_Training_Dataset.zip\" \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4279bb58",
   "metadata": {},
   "source": [
    "#!unzip \"MedNIST_Training_Dataset.zip\" -d \"/content/drive/MyDrive/Colab Notebooks/2022_02_09_MedNIST/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510d99bb",
   "metadata": {},
   "source": [
    "#from PIL import Image\n",
    "#Image.open('MedNIST Training Dataset/CXR/006568.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c44cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "import tensorflow\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f71e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", None)\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "pd.set_option(\"max_row\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405d0d2d",
   "metadata": {},
   "source": [
    "### 1 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31e369ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'Data'\n",
    "dataset_ab = dataset_dir + '/AbdomenCT'\n",
    "dataset_br = dataset_dir + '/BreastMRI'\n",
    "dataset_ct = dataset_dir + '/ChestCT'\n",
    "dataset_c = dataset_dir + '/CXR'\n",
    "dataset_hd = dataset_dir + '/Hand'\n",
    "dataset_h = dataset_dir + '/HeadCT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e5c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "path_ab = dataset_ab\n",
    "num_files_ab = len([f for f in os.listdir(path_ab)\n",
    "                if os.path.isfile(os.path.join(path_ab, f))])\n",
    "path_br = dataset_br\n",
    "num_files_br = len([f for f in os.listdir(path_br)\n",
    "                if os.path.isfile(os.path.join(path_br, f))])\n",
    "path_ct = dataset_ct\n",
    "num_files_ct = len([f for f in os.listdir(path_ct)\n",
    "                if os.path.isfile(os.path.join(path_ct, f))])\n",
    "path_c = dataset_c\n",
    "num_files_c = len([f for f in os.listdir(path_c)\n",
    "                if os.path.isfile(os.path.join(path_c, f))])\n",
    "path_hd = dataset_hd\n",
    "num_files_hd = len([f for f in os.listdir(path_hd)\n",
    "                if os.path.isfile(os.path.join(path_hd, f))])\n",
    "path_h = dataset_h\n",
    "num_files_h = len([f for f in os.listdir(path_h)\n",
    "                if os.path.isfile(os.path.join(path_h, f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a6b5680",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = num_files_ab + num_files_br + num_files_ct + num_files_c + num_files_hd + num_files_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0632ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d011e1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47169 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(dataset_dir,\n",
    "                                            target_size = (64, 64),                                             \n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode=\"categorical\"                                             \n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80fde899",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_generator[0][0]\n",
    "y_train = train_generator[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a765a89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47169, 64, 64, 3), (47169, 6))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9af7e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMG_SHAPE = (64, 64, 3)\n",
    "vgg = VGG16(input_shape = IMG_SHAPE, include_top = False,\n",
    "            weights=\"imagenet\")\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1e0bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = vgg.predict(train_generator[0][0]).reshape(batch_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e23d61c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47169, 2048)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafd443b",
   "metadata": {},
   "source": [
    "### 2 - save le jeu de train in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf552599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('feature_train_all', feature_train_all)\n",
    "#np.save('y_train_all', y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e5a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('X_train_all', X_train_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3f4682",
   "metadata": {},
   "source": [
    "### 3 - charger le jeu de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb33466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_train = np.load('feature_train_all.npy')\n",
    "#X_train = np.load('X_train_all.npy')\n",
    "#y_train = np.load('y_train_all.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ffba3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list = y_train.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044901db",
   "metadata": {},
   "source": [
    "### 5 - load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a699e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_lr = joblib.load('logreg_model_final.jb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6ace1b",
   "metadata": {},
   "source": [
    "### 6 - model predict (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6857e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "y_train_pred = best_model_lr.predict(feature_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e516a8",
   "metadata": {},
   "source": [
    "### 7 - confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f53269a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8000,    0,    0,    0,    0,    0],\n",
       "       [   0, 7163,    0,    0,    0,    0],\n",
       "       [   0,    0, 8000,    0,    0,    0],\n",
       "       [   0,    0,    0, 8000,    0,    0],\n",
       "       [   0,    0,    0,    0, 8000,    0],\n",
       "       [   0,    0,    0,    0,    0, 8006]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_train = confusion_matrix(y_train_list, y_train_pred)\n",
    "cm_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4c033c",
   "metadata": {},
   "source": [
    "### 8 - accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33b7b956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_train_list, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25797e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      1.00      1.00      7163\n",
      "           2       1.00      1.00      1.00      8000\n",
      "           3       1.00      1.00      1.00      8000\n",
      "           4       1.00      1.00      1.00      8000\n",
      "           5       1.00      1.00      1.00      8006\n",
      "\n",
      "    accuracy                           1.00     47169\n",
      "   macro avg       1.00      1.00      1.00     47169\n",
      "weighted avg       1.00      1.00      1.00     47169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train_list, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c6315a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db1c12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e7ed7de",
   "metadata": {},
   "source": [
    "https://teratail.com/questions/221722"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c28bfe",
   "metadata": {},
   "source": [
    "https://qiita.com/gp333/items/f88216733c5336d5b423"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb530a6",
   "metadata": {},
   "source": [
    "https://note.com/abechanta/n/n0f198a483102"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a61ea",
   "metadata": {},
   "source": [
    "https://recruit.gmo.jp/engineer/jisedai/blog/transfer-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d48c819",
   "metadata": {},
   "source": [
    "https://www.tsl.co.jp/ai-seminar-contents-04/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b033944d",
   "metadata": {},
   "source": [
    "https://qiita.com/ps010/items/dee9413d3de28de7d2f9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab1da71",
   "metadata": {},
   "source": [
    "ロジスティック回帰\n",
    "https://aidemy.net/magazine/652/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba63cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648ff483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f6d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8fa1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7362520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29f627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6358cbde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e184fbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
